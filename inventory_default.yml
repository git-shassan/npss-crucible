all:
  vars:
    ##################################
    # Assisted Install Configuration #
    ##################################
    # These options configure Assisted Installer and the resulting cluster
    # https://generator.swagger.io/?url=https://raw.githubusercontent.com/openshift/assisted-service/58a6abd5c99d4e41d939be89cd0962433849a861/swagger.yaml
    # See section: cluster-create-params

    # Cluster name and dns domain combine to give the cluster namespace that will contain OpenShift endpoints
    # e.g. api.clustername.example.lab, worker1.clustername.example.lab
    cluster_name: mano-npss
    base_dns_domain: jnpr.bos2.lab

    # OpenShift version (4.6.16, 4.7.33, 4.8.14 or 4.9.0)
    openshift_full_version: 4.10.3

    # ai_version: v1.0.24.2
    supported_ocp_versions:
      - 4.10.3
    ocp_release_versions_map_all:
      '4.10': 4.10.3
    assisted_service_openshift_versions_defaults:
        "4.10":
          display_name: 4.10.3
          release_image: quay.io/openshift-release-dev/ocp-release:4.10.13-x86_64
          release_version: 4.10.3
          rhcos_image: https://mirror.openshift.com/pub/openshift-v4/dependencies/rhcos/4.10/4.10.3/rhcos-4.10.3-x86_64-live.x86_64.iso
          rhcos_rootfs: https://mirror.openshift.com/pub/openshift-v4/dependencies/rhcos/4.10/4.10.3/rhcos-live-rootfs.x86_64.img
          rhcos_version: 410.84.202202251620-0
          support_level: production

    # Virtual IP addresses used to access the resulting OpenShift cluster
    api_vip: 192.168.12.91 # the IP address to be used for api.clustername.example.lab and api-int.clustername.example.lab
    ingress_vip: 192.168.12.92 # the IP address to be used for *.apps.clustername.example.lab

    ## Allocate virtual IPs via DHCP server. Equivalent to the vip_dhcp_allocation configuration option of Assisted Installer
    vip_dhcp_allocation: false

    # The subnet on which all nodes are (or will be) accessible.
    machine_network_cidr: 192.168.12.0/25 

    # The IP address pool to use for service IP addresses
    service_network_cidr: 172.30.0.0/16

    # Cluster network settings. You are unlikely to need to change these
    cluster_network_cidr: 10.128.0.0/14 # The subnet, internal to the cluster, on which pods will be assigned IPs
    cluster_network_host_prefix: 23 # The subnet prefix length to assign to each individual node.

    # # Cluster network provider. Cannot be changed after cluster is created.
    # # The default is OpenShift SDN unless otherwise specified.
    network_type: OVNKubernetes
    # network_type: OpenShiftSDN

    ######################################
    # Prerequisite Service Configuration #
    ######################################

    # Flags to enable/disable prerequisite service setup
    # You will need to ensure alternatives are available for anything that will not be automatically set up
    setup_ntp_service: true
    setup_dns_service: true
    setup_pxe_service: false
    setup_registry_service: false # Only required for a Restricted Network installation
    setup_http_store_service: true
    setup_assisted_installer: true # default is true you may wish to turn it off if multiple users are using the same instance.


    # NTP Service
    # ntp_server is the address at which the NTP service is (or will be) available
    ntp_server: 192.168.2.49
    # ntp_server_allow is the range of IPs the NTP service will respond to
    ntp_server_allow: 192.168.12.0/25 # not required if setup_ntp_service is false


    # Mirror Registry Service parameters for a Restricted Network installation

    # use_local_mirror_registry controls if the install process uses a local container registry (mirror_registry) or not.
    # Set this to true to use the mirror registry service set up when `setup_registry_service` is true.
    use_local_mirror_registry: false

    # HTTP Store Configuration
    # ISO name must include the `discovery` directory if you have a SuperMicro machine
    discovery_iso_name: "discovery/{{ cluster_name }}/discovery-image.iso"

    # discovery_iso_server must be discoverable from all BMCs in order for them to mount the ISO hosted there.
    # It is usually necessary to specify different values for KVM nodes and/or physical BMCs if they are on different subnets.
    discovery_iso_server: "http://{{ hostvars['http_store']['ansible_host'] }}"

    ############################
    # Local File Configuration #
    ############################

    repo_root_path: /home/mano/mano-npss/ # path to repository root

    # Directory in which created/updated artifacts are placed
    fetched_dest: "{{ repo_root_path }}/fetched"

    # Configure possible paths for the pull secret
    # first one found will be used
    # note: paths should be absolute
    pull_secret_lookup_paths:
      - "{{ fetched_dest }}/pull-secret.txt"
      - "{{ repo_root_path }}/pull-secret.txt"

    # Configure possible paths for the ssh public key used for debugging
    # first one found will be used
    # note: paths should be absolute
    ssh_public_key_lookup_paths:
      - "{{ fetched_dest }}/ssh_keys/{{ cluster_name }}.pub"
      - "{{ repo_root_path }}/ssh_public_key.pub"
      - ~/.ssh/id_rsa.pub

    # Set the base directory to store ssh keys
    ssh_key_dest_base_dir: /home/mano/mano-npss

    # The retrieved cluster kubeconfig will be placed on the bastion host at the following location
    kubeconfig_dest_dir: /home/mano/mano-npss/
    kubeconfig_dest_filename: "{{ cluster_name }}-kubeconfig"
    kubeadmin_dest_filename: "{{ cluster_name }}-kubeadmin.vault.yml"
    # You can comment out the line below if you want the kubeadmin credentials to be stored in plain text
    # kubeadmin_vault_password_file_path: "{{ repo_root_path }}/kubeadmin_vault_password_file"

    ############################
    #    LOGIC: DO NOT TOUCH   #
    # vvvvvvvvvvvvvvvvvvvvvvvv #
    ############################

    # pull secret logic, no need to change. Configure above
    local_pull_secret_path: "{{ lookup('first_found', pull_secret_lookup_paths) }}"
    pull_secret: "{{ lookup('file', local_pull_secret_path) }}"

    # ssh key logic, no need to change. Configure above
    local_ssh_public_key_path: "{{ lookup('first_found', ssh_public_key_lookup_paths) }}"
    ssh_public_key: "{{ lookup('file', local_ssh_public_key_path) }}"

    # provided mirror certificate logic, no need to change.
    local_mirror_certificate_path: "{{ (setup_registry_service == true) | ternary(
        fetched_dest + '/' + (hostvars['registry_host']['cert_file_prefix'] | default('registry')) + '.crt',
        repo_root_path + '/mirror_certificate.txt')
      }}"
    mirror_certificate: "{{ lookup('file', local_mirror_certificate_path) }}"

    openshift_version: "{{ openshift_full_version.split('.')[:2] | join('.') }}"

    is_valid_single_node_openshift_config: "{{ (groups['nodes'] | length == 1) and (groups['masters'] | length == 1) }}"

    ############################
    # ^^^^^^^^^^^^^^^^^^^^^^^^ #
    #    LOGIC: DO NOT TOUCH   #
    ############################


  children:
    bastions: # n.b. Currently only a single bastion is supported
      hosts:
        bastion:
          ansible_host:  192.168.12.49 # Must be reachable from the Ansible control node
          ansible_connection: local # if your are not running crucible from the bastion then remove this line

    # Configuration and access information for the pre-requisite services
    # TODO: document differences needed for already-deployed and auto-deployed
    services:
      hosts:
        assisted_installer:
          ansible_host: 192.168.12.49 
          host: 192.168.12.49 #internal GW IP 
          port: 8090 # Do not change

        registry_host:
          ansible_host: 192.168.12.49 # TBD
          registry_port: 5000
          registry_fqdn: bastion-reg.jnpr.bos2.lab  # --registry.example.lab # use in case of different FQDN for the cert
          # cert_common_name: "{{ registry_fqdn }}"
          cert_country: US
          cert_locality: Raleigh
          cert_organization: Red Hat, Inc.
          cert_organizational_unit: Lab
          cert_state: NC

          # Configure the following secret values in the inventory.vault.yml file
          REGISTRY_HTTP_SECRET: "{{ VAULT_REGISTRY_HOST_REGISTRY_HTTP_SECRET | mandatory }}"
          disconnected_registry_user: "{{ VAULT_REGISTRY_HOST_DISCONNECTED_REGISTRY_USER | mandatory }}"
          disconnected_registry_password: "{{ VAULT_REGISTRY_HOST_DISCONNECTED_REGISTRY_PASSWORD | mandatory }}"

        dns_host:
          ansible_host: 192.168.12.49
          upstream_dns: 192.168.12.10     # 192.168.12.10 #internal bastion IP -- # an optional upstream dns server
          listen_addresses:
            - 192.168.12.49
          # The following are required for DHCP setup
          # use_dhcp: true
          # use_pxe: false
          # dhcp_range_first: 10.60.2.1
          # dhcp_range_last:  10.60.2.200
          # prefix: 24
          # gateway: 10.60.2.254  #internal bastion IP same subnet - 10.60.0.1
          #          extra_dns_records:
          #            registry:
          #              use_dhcp: true 
          #              name: bastion-reg.jnpr.bos2.lab
          #              address: bastion-reg.jnpr.bos2.lab
          #              ip: 10.60.2.254
        
        http_store:
          ansible_host: 192.168.12.49
        
          # tftp_host:
          # ansible_host: "{{ hostvars['dns_host']['ansible_host'] }}"
          # tftp_directory: /var/lib/tftpboot/ 

        ntp_host:
          ansible_host: 192.168.12.49

    # Describe the desired cluster members
    nodes:
      # A minimum of three master nodes are required. More are supported.
      # Worker nodes are not required, but if present there must be two or more.
      #
      # Node Required Vars:
      # - role
      #     - Must be either "master" or "worker", and must match the group
      #
      # - mac
      #     - The MAC address of the node, used as a hardware identifier by Assisted Installer.
      #     - The value set here will be used when creating VMs and must be unique within the network.
      #
      # - vendor
      #     - One of "Dell", "HPE", "Lenovo", "SuperMicro", "KVM", "PXE" as the supported BMC APIs.
      #     - "KVM" identifies a node as a VM to be created. If a "KVM" node is present,
      #       then a "vm_host" must be defined in the node and a host with that name must exist
      #       inside the "vm_hosts" group. 
      #     - "PXE" identifies a node as a baremetal that needs to boot from PXE.
      #
      # - bmc_address
      # - bmc_user
      # - bmc_password
      #     - details for the BMC that controls the node.
      #     - Must be set to the vm_host for "KVM" nodes.
      #
      # Static IP Vars:
      #   See docs/inventory.md: Network configuration section
      #
      # Optional Vars:
      # - vm_spec
      #     - Specifications for the node:
      #          - cpu_cores
      #          - ram_mib
      #          - disk_size_gb
      #
      # - installation_disk_path
      #     - The value set here will be used by Assisted Installer as the installation disk device
      #       for a given host.
      #     - The value must be a path to the disk device, e.g. /dev/sda
      #     - If not specified, Assisted Installer will pick the first enumerated disk device for a
      #       given host.
      vars:
        # Set the login information for any BMCs. Note that these will be SET on the vm_host virtual BMC.
        bmc_user: "{{ VAULT_NODES_BMC_USER | mandatory }}"
        bmc_password: "{{ VAULT_NODES_BMC_PASSWORD | mandatory }}"
        dns1: 192.168.12.49
        gateway: 192.168.12.1
        bond0_mask: 25
                #network_config:
                #          interfaces:
                #            - name: bond0
                #              type: bond
                #              state: up
                #              link_aggregation:
                #                mode: '802.3ad'
                #                options:
                #                  miimon: "1500"
                #                  #lacp_rate: "fast"
                #                slaves:
                #                - ens4f0
                #                - ens4f1
                #            - name: ens4f0
                #              type: ethernet
                #              mac: "{{ mac }}"
                #              state: down
                #            - name: ens4f1
                #              type: ethernet
                #              mac: "{{ mac2 }}"
                #              state: down
                #            - name: vlan12
                #              type: vlan
                #              state: up
                #              addresses:
                #                ipv4:
                #                - ip: "{{ ansible_host }}"
                #                  prefix: "{{ bond0_mask }}"
                #              vlan:
                #                base-iface: bond0
                #                id: 12
        network_config:
          interfaces:
            - name: ens4f0
              type: ethernet
              mac: "{{ mac }}"
              state: up
            - name: vlan12
              type: vlan
              state: up
              addresses:
                ipv4:
                - ip: "{{ ansible_host }}"
                  prefix: "{{ bond0_mask }}"
              vlan:
                base-iface: ens4f0
                id: 12
          dns_server_ips:
            - "{{ dns1 }}"
          routes:
            - destination: 0.0.0.0/0
              address: "{{ gateway }}"
              interface: ens4f0
      children:
        masters:
          vars:
            role: master
            vendor: Dell 
          hosts:
            master1:
              ansible_host: 192.168.12.80
              mac: "b4:96:91:b6:2a:8e" 
              bmc_address: 192.168.12.141 #"vm_host.clustername.example.lab:8082" # port can be changed using sushy_tools_port on the vm_host

              # # Uncomment to set custom BMC credentials for the node
              # # These variables must be set in the inventory.vault.yml file
              bmc_user: "{{ VAULT_NODES_SUPER1_BMC_USER | mandatory }}"
              bmc_password: "{{ VAULT_NODES_SUPER1_BMC_PASSWORD | mandatory }}"

            master2:
              ansible_host: 192.168.12.81
              mac:  "b4:96:91:B6:2b:f0"
              bmc_address: 192.168.12.140 #"vm_host.clustername.example.lab:8082" # port can be changed using sushy_tools_port on the vm_host

            master3:
              ansible_host: 192.168.12.82
              mac: "b4:96:91:b6:29:76"
              bmc_address: 192.168.12.169 #"vm_host.clustername.example.lab:8082" # port can be changed using sushy_tools_port on the vm_host
